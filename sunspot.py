# -*- coding: utf-8 -*-
"""Sunspot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZTapS2cUg3mbGOggo9vT6ASSIsM0uwdw
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Dropout
from sklearn.metrics import mean_squared_error

from tensorflow.random import set_seed
from random import seed

import seaborn as sns
# sns.set()
import matplotlib.pyplot as plt

SEED = 3
seed(SEED)
np.random.seed(SEED)
set_seed(SEED)

from google.colab import drive
drive.mount('/content/gdrive')

data = pd.read_csv("/content/gdrive/MyDrive/Colab Notebooks/dataset/sunspots_data.csv")

data.head()

data.describe()

"""The average spots noticed on the flowers is 81.76. 75% of the flower spots are below the average while 25% is is above the mean.

# Data Engineering
"""

#Converting the Month column into timestamp
data['Month'] = pd.to_datetime(data['Month'])

#Renaming the Month column as time stamp
data.rename(columns = {'Month': 'TimeStamp'}, inplace=True)

# Visualizing the entire dataset

plt.figure(figsize=(12, 6))
plt.plot(data['TimeStamp'], data['Sunspot Number'], linestyle='-')
plt.title('Time Plot of Sunspot Number')
plt.xlabel('Time Stamp')
plt.ylabel('Sunspot Number')
plt.grid(True)
plt.show()

#Splitting the data into 80% train and 20% test
t_end = 0.8*len(data)
t_end = int(t_end//1)

len(data), t_end

train_data, test_data = data.iloc[:t_end,1].values.reshape(-1,1), data.iloc[t_end:,1].values.reshape(-1,1)

scaler = MinMaxScaler()
scaler.fit(train_data)
train_data = scaler.transform(train_data)
test_data = scaler.transform(test_data)

train_data.shape, test_data.shape

def splitSequence(seq, n_steps):
    # Creating empty list variables
    X, y = [], []
    for i in range(len(seq)):
        lastIndex = i + n_steps
        if lastIndex > len(seq) - 1:
            break
        #Creating input and output sequence
        seq_X, seq_y = seq[i:lastIndex], seq[lastIndex]
        #appending seq_X, seq_y ti the empty list
        X.append(seq_X)
        y.append(seq_y)
    #Converting X and y into numpy array
    return  np.array(X), np.array(y)

# Feeding in 50 sequence of data into the model
# Every n_steps + 1 data point will be the 'y' values
n_steps = 10

#Splitng data into train and train data.
X_train, y_train = splitSequence(train_data, n_steps)
X_test, y_test = splitSequence(test_data, n_steps)

#checking the shapes of the train and test data
X_train.shape, y_train.shape, X_test.shape, y_test.shape

y_train

# Preping the train and test data for the model.
n_features = 1

X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))

X_train.shape

model = Sequential()
model.add(GRU(100, activation='tanh', return_sequences=True, input_shape=(n_steps, n_features)))
model.add(SimpleRNN(50, activation='relu', return_sequences=True))
model.add(GRU(50, activation='tanh', return_sequences=True))
model.add(SimpleRNN(50, activation='relu', return_sequences=True))
model.add(LSTM(50, activation='tanh', return_sequences=True))
model.add(Dense(50, activation='relu')) # introducing relu activation function to introduce non-linearity into the model
model.add(Dense(1, activation='sigmoid'))# Output layer for binary classification with sigmoid activation

# Compiling the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])

model.summary()

model.fit(X_train, y_train, epochs=20, verbose=2)

loss = model.evaluate(X_test, y_test, verbose=2)
print(loss)
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# invert the scaling back to the original
y_train = scaler.inverse_transform(y_train.reshape(-1,1))
y_test = scaler.inverse_transform(y_test.reshape(-1,1))
y_pred_train = scaler.inverse_transform(y_pred_train.reshape(-1,1))
y_pred_test = scaler.inverse_transform(y_pred_test.reshape(-1,1))

actual = np.append(y_train, y_test)
prediction = np.append(y_pred_train, y_pred_test)
# plot the sequence and predictions
fig, ax = plt.subplots(1,1, figsize=(10, 4))
ax.plot(actual, label='Actual')
ax.plot(prediction, label='Predictions')
#ax.plot(range(0,81), data, label='Predictions')

ax.axvline(x=len(y_train), color='r')
ax.legend()
ax.set_xlabel('Time Step')
ax.set_ylabel('Sales')
ax.set_title('Number of Sun Spots.  ' +
    'The Red Line Separates The Training And Validation Data')

fig.tight_layout()