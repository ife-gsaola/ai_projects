# -*- coding: utf-8 -*-
"""Credit_Risk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11k0dUee2pM2OMUXlOjb_Uz4IRHKqnlGy
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from sklearn.preprocessing import MinMaxScaler
import seaborn as sns
sns.set(style="whitegrid")

from google.colab import drive
drive.mount('/content/gdrive')

data = pd.read_csv("/content/gdrive/MyDrive/Colab Notebooks/dataset/UCI_Credit_Card.csv")

data_to_clean = data.copy()
data_without_id = data_to_clean.drop('ID', axis=1)

data_without_id.describe()

data_to_clean.head()

"""# **Taking a look at:**

1. How many people defaults overall?
2. what is the proportion of education to defauting
3. Age group of defaulters
4. Will be interesting to see if people started defaulting when they clocked retirement?


According to ChatGPT, Bill Statement is a document that provides a summary of financial transactions between two parties over a specific period. It is commonly associated with various types of accounts, such as credit cards, utility services, subscriptions, or loans. **The purpose of a bill statement is to inform the recipient of the charges, payments, and other relevant details related to the account**.

"""

# data_to_clean.isnull().sum() # No null data

# Renamed the predictor column

data_to_clean.rename(columns={'default.payment.next.month':'_default'}, inplace=True)

"""# **Feature Engineering**"""

# data_to_clean.columns
columns = ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',
       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',
       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',
       '_default']

data_to_clean['total_bill'] = data_to_clean.iloc[:,11:17].sum(axis=1)
data_to_clean['total_payment'] = data_to_clean.iloc[:,17:23].sum(axis=1)

'''
Credit utilization ratio is the ratio of credit used to the total credit available.
A good credit utilization ratio is such that is kept under 30%.
Credit utilization ratio above 30% is usually considered as
'''

data_to_clean['Credit_util_ratio'] = (data_to_clean['total_bill']-data_to_clean['total_payment'])/data_to_clean['LIMIT_BAL']*100
# data_to_clean

# abnormal = data_to_clean[(data_to_clean[['Credit_util_ratio']]>100).all(axis=1)]
# abnormal

# data_to_clean['AGE'].max()
age_bin = [0, 16, 25, 35, 64, 100]
_group = ['0-15', '16-24', '25-34','35-64', '65+']

data_to_clean['age_group'] = pd.cut(data_to_clean['AGE'], bins=age_bin, labels=_group, right=False)
data_to_clean['age_group'] = pd.Categorical(data_to_clean['age_group'], categories=_group)

"""# **EDA**"""

plt.figure(figsize=(6, 4))

sns.regplot(x='LIMIT_BAL', y='total_bill', data=data_to_clean, scatter_kws={'s': 50}, line_kws={'color': 'red'})

# Set labels and title
plt.xlabel('Total Bill ($)')
plt.ylabel('Tip ($)')
plt.title('Scatter Plot of Total Bill vs Tip')

# Show the legend
plt.legend(title='Gender')

plt.figure(figsize=(6, 4))
sns.barplot(x='age_group', y='total_bill', data=data_to_clean, ci=None)
plt.title('Age vs Total Bill')
plt.xlabel('Age Total Bill')
plt.ylabel('Age')
plt.show()

categorical_features = ['ID', 'SEX', 'EDUCATION', 'MARRIAGE','LIMIT_BAL', 'total_bill', 'total_payment']

sex_map = {1:"male", 2:"female"}
edu_map = {1:'graduate school', 2:'university', 3:'high school', 4:'others', 5:'unknown', 6:'unknown'}
mage_map = {1:'married', 2:'single',3:'others'}

categorical_data = data_to_clean[categorical_features]

categorical_data['SEX'].replace(sex_map, inplace=True)
categorical_data['EDUCATION'].replace(edu_map, inplace=True)
categorical_data['MARRIAGE'].replace(mage_map, inplace=True)

plt.figure(figsize=(9, 5))
sns.barplot(x='EDUCATION', y='total_bill', data=categorical_data, ci=None)
plt.title('Education vs Total Bill')
plt.xlabel('Education Total Bill')
plt.ylabel('Total Bill')
plt.show()

plt.figure(figsize=(9, 5))
sns.barplot(x='EDUCATION', y='total_payment', data=categorical_data, ci=None)
plt.title('Education vs Limit Balance')
plt.xlabel('Education Limit Balance')
plt.ylabel('Limit Balance')
plt.show()

plt.figure(figsize=(9, 5))
sns.barplot(x='MARRIAGE', y='total_payment', data=categorical_data, ci=None)
plt.title('Education vs Limit Balance')
plt.xlabel('Education Limit Balance')
plt.ylabel('Limit Balance')
plt.show()

negative_columns = ['BILL_AMT1', 'BILL_AMT2',
       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']
negative_data = data_to_clean[(data_to_clean[negative_columns]<0).all(axis=1)]

clean_data = data_to_clean[(data_to_clean[negative_columns]>=0).all(axis=1)]

# a = data_to_clean.groupby('age_group')['total_bill'].sum()

clean_data_columns = ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',
       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',
       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',
       'total_bill', 'total_payment', 'Credit_util_ratio', '_default']

clean_data = clean_data[clean_data_columns]

from sklearn.model_selection import train_test_split

X = clean_data.iloc[:,:len(clean_data_columns)-1]
y = clean_data['_default']

clean_data['_default'].value_counts()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 40)

from imblearn.combine import SMOTETomek
smote = SMOTETomek(sampling_strategy =0.8, random_state=40 )
X_res,y_res=smote.fit_resample(X_train,y_train)

y_train.value_counts()
y_res.value_counts()

scaler = MinMaxScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# Placeholder function for defining hyperparameter grids
def get_hyperparameter_grid(model_name):
    if model_name == 'Logistic Regression':
        return {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'max_iter': [100, 200, 300]}

    elif model_name == 'Decision Tree':
        return {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}

    elif model_name == 'XGBoost':
        return {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]}

    else:
        raise ValueError(f"Unsupported model: {model_name}")

binary_classification_models = {
    'Logistic Regression': LogisticRegression(solver='liblinear', max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(),
    'XGBoost': XGBClassifier()
}

# Dictionary to store best hyperparameters for each model
best_hyperparameters = {}

# Loop through each model for hyperparameter tuning and evaluation
for model_name, model in binary_classification_models.items():
    print(f"\n--- {model_name} ---")

    # Hyperparameter tuning using grid search
    param_grid = get_hyperparameter_grid(model_name)  # Define your hyperparameter grid
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')
    grid_search.fit(X_res,y_res)

    # Get the best hyperparameters
    best_hyperparameters[model_name] = grid_search.best_params_

    # Train the final model with the best hyperparameters
    final_model = grid_search.best_estimator_
    final_model.fit(X_res,y_res)

    # Evaluate the model on the test set
    y_pred = final_model.predict(X_test)

    # Print evaluation metrics
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Best Hyperparameters: {best_hyperparameters[model_name]}")
    print(f"Accuracy on Test Set: {accuracy:.4f}")

# cor = data_to_clean.corr()
# plt.figure(figsize=(20,7))
# sns.heatmap(cor, annot=True, cmap = plt.cm.CMRmap_r)
# plt.show ()

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

cm

from sklearn.metrics import confusion_matrix
balanced_cm = confusion_matrix(y_test, y_pred)

balanced_cm

"""# **Limitations of the dataset**

1. No information about the employment status of the customers, while age can provide insight into this, it is not wholesome.
2. No information about the country/economic situation of the country, e.g., inflation, as this is also a major factor that affects spendings of customers.

# **Outliers**

In credit risk data, a high values may not indicate the present of outlier. It may be the true representation of the customer's earning and debt profile. Therefore, all values are left intact and scaled before fed into the model.
"""