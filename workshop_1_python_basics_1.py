# -*- coding: utf-8 -*-
"""Workshop_1_Python Basics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lr0IG-XweI6h0ure4y9j5EmoMyFBC89n
"""



"""## EXAMPLES"""

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

"""## Importing a dataset for this workshop

## Importing the dataset directly from the source
"""

# Installing a package which is needed to download the dataset from its online source. This package is recommended by the online source at the following
# URL : https://archive.ics.uci.edu/dataset/2/adult
!pip3 install ucimlrepo

# Downloading the dataset from the online source. The first two lines are given by the online source mentioned above
from ucimlrepo import fetch_ucirepo
# fetch dataset
adult = fetch_ucirepo(id=2)

# Putting data in a pandas dataframe
X = adult.data.features
y = adult.data.targets
data=pd.concat([X,y],axis=1)

adult

#printing data
data

"""## Importing the dataset from a folder on your local disk"""

#importing the dataset as a Pandas DataFrame into Python if the dataset is stored on your local hard disk
# You can download the dataset from the following URL: https://archive.ics.uci.edu/dataset/2/adult
data = pd.read_csv('adult.csv') # Replace the current data path with the data path on your local disk

"""## Exploring the dataset"""

# Showing the first 5 rows of the dataset
data.head()

# Finding the shape of the data
print(data.shape)

# Generate a dataset by randomly extracting 30000 rows (samples)
data_new = data.sample(n=30000, random_state = 48)

# Printing the new dataset
data_new

# The indices of different rows in the dataset are currently messy. This happens in many data science projects. Always reindex
# the dataset if you are unsure the indices are correct.
data_new.reset_index(drop=True, inplace=True)

# Checking if the indices are correct
data_new

data

# Getting statistical information of the dataset for different columns (features)
data.describe(include="all")

# Droping row with Null values (This topic will be discussed in detail in the next lecture)
data.dropna(inplace=True)

data

"""NOTE: As you can see, because a few rows have been dropped, the index numbers don't correspond to the actual row number (the number of rows is 47623 but the last index is 48841). We need to reindex the data"""

# reindexing the original data
data.reset_index(drop=True, inplace=True)

data

# Getting the number of Null values for different columns
data.isna().sum()

# Showing the dataset information
data.info()

data.shape

# Getting the count of different values in the column "education-num"
data['education-num'].value_counts()

# Getting the count of different values in the column "education"
data['education'].value_counts()

# Dropping a column
data = data.drop(['fnlwgt'], axis=1)

data.shape

# Getting the number of unique values of a column
data['education'].nunique()

# Finding how many rows are related to either gender
data['sex'].value_counts()

# Calculating the average age of different genders in the dataset
data['age'].groupby([data['sex']]).mean()

# Getting the average age of different genders in the dataset broken down based on their education
data['age'].groupby([data['sex'],data['education']]).mean()

# Getting the maximum age of different races in the dataset
data['age'].groupby([data['race']]).max()

# Extracting the age and education columns and creating a new DataFrame using these columns
a=data['age']
b=data['education']
new_data=pd.concat([a,b],axis=1)

data

"""* Q10: Write a function that receives the dataset and replace Famle with F and Male with M (please try to write it yourself before checking the answer in the next cell)"""

# Answer
def encode_sex(data):
    rows=data.shape[0]
    a=data.loc[:,'sex']
    for i in range(rows):
        if a[i]=="Male":
            data.loc[i,"sex"]="M"
        elif a[i]=="Female":
            data.loc[i,"sex"]="F"
    return data

# Copying the data
data_copy=data.copy()

# Applying the encode_sex function to the copied data
data_encoded=encode_sex(data_copy)
data_encoded.head()

data

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np

############# WRITE THE CODE IN THIS CELL ####################
original_dataset = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/DATA MINING/adult.csv")

# Generate a new dataset with 10,000 random samples
task_dataset = original_dataset.sample(n=10000, random_state=42)

print(task_dataset.shape)

# converting the unknown value '?' to na in the dataset
task_dataset.replace('?', np.nan, inplace=True)
print(task_dataset.isna().sum())

# Reindex the generated dataset
task_dataset.reset_index(drop=True, inplace=True)

# Remove NULL values
task_dataset.dropna(inplace=True)

# Display the first few rows of the new dataset
# print(task_dataset.head())
print(task_dataset.shape)

task_dataset.head()

"""############ WRITE EXPLANATIONS HERE (IF APPLICABLE) #############



"""

############# WRITE THE CODE IN THIS CELL ####################
# Group by 'sex' and calculate the average capital-gain for each sex
average_capital_gain_by_sex = task_dataset.groupby('sex')['capital-gain'].sum()
print(f"Contribution of Sex to average capital gain is: \n {average_capital_gain_by_sex}")

# Group by 'occupation' and calculate the total capital-gain for each occupation
total_capital_gain_by_occupation = task_dataset.groupby('occupation')['capital-gain'].sum()
print(f"Contribution of Occupation to average capital gain is: \n {total_capital_gain_by_occupation}")

"""############ WRITE EXPLANATIONS HERE (IF APPLICABLE) #############



"""

############# WRITE THE CODE IN THIS CELL ####################

# Group by 'education' and 'native-country', then count the occurrences
education_counts_by_country = task_dataset[task_dataset['education'] == 'Bachelors'].groupby('native-country').size()
sorted_countries = education_counts_by_country.sort_values(ascending=False)

# Find the country with the highest number of people with a Bachelor's degree
country_with_highest_bachelors = education_counts_by_country.idxmax()
print(f"The country with the highest bachelor's degree is: {country_with_highest_bachelors}")

############# WRITE THE CODE IN THIS CELL ####################

def print_greetings(names, ages):
    for name, age in zip(names, ages):
        print(f"Hello {name} {age}")

# Example usage:
names = ['Amin', 'Michael', 'Timi', 'Ifeoluwa', 'Seun']
ages = [27, 38, 20, 23, 34]
print_greetings(names, ages)

"""############ WRITE EXPLANATIONS HERE (IF APPLICABLE) #############



"""

############# WRITE THE CODE IN THIS CELL ####################
def capitalize_words(optional_text):
    words = optional_text.upper()
    print("Capitalized words: %s" % words)


capitalize_words('Write a code to receive an optional text, capitalise all words in the text and print them')

"""############ WRITE EXPLANATIONS HERE (IF APPLICABLE) #############



"""

import pandas as pd

def split_and_swap(dataset):
    num_columns = len(dataset.columns)
    half_columns = num_columns // 2w

    for column in range(half_columns):
        dataset.iloc[:, column], dataset.iloc[:, column + half_columns] = dataset.iloc[:, column + half_columns].copy(), dataset.iloc[:, column].copy()

split_and_swap(task_dataset)

task_dataset

############# WRITE THE CODE IN THIS CELL####################

def compare_columns(dataset, column1, column2):
    dataset['comparison_result'] = dataset[column1] > dataset[column2]

# Example usage:
# Assuming `task_dataset` is your DataFrame
compare_columns(task_dataset, 'age', 'hours-per-week')

print(task_dataset)

"""############ WRITE EXPLANATIONS HERE (IF APPLICABLE) #############



"""

def max_min_avg_age_countries(dataset):
    # Convert 'age' column to numeric type, ignoring errors
    dataset['age'] = pd.to_numeric(dataset['age'], errors='coerce')

    # Group the dataset by 'native-country' and calculate the average age for each country
    avg_age_by_country = dataset.groupby('native-country')['age'].mean()

    # Find the country with the maximum average age
    max_avg_age_country = avg_age_by_country.idxmax()

    # Find the country with the minimum average age
    min_avg_age_country = avg_age_by_country.idxmin()

    return max_avg_age_country, min_avg_age_country

# Example usage:
max_country, min_country = max_min_avg_age_countries(task_dataset)
print("Country with maximum average age:", max_country)
print("Country with minimum average age:", min_country)