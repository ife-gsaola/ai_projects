# -*- coding: utf-8 -*-
"""Saola Gbenga_2330243_DNN_FlowerData.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/153-yE6v9h7T7H8BNfStUcMwITeeVxhdi
"""

# Data handling libraries
import pandas as pd
import numpy as np

# Tensorflow and keras libraries for model construction
import tensorflow as tf
from tensorflow.keras import Sequential, models, optimizers, layers
from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Dropout, BatchNormalization, Activation
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard

# Sklearn libraries for data preprocessing and model evaluation
from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler

#Visualization library
import matplotlib.pyplot as plt
import seaborn as sns

sns.set()

from google.colab import drive
drive.mount('/content/gdrive')

data = pd.read_csv("/content/gdrive/MyDrive/Colab Notebooks/dataset/flower_data.csv")

data.head()

data.describe()

plt.hist(data['X1'])
plt.xlabel('X1')
plt.title('Variable distribution plot of X1')
plt.show()

plt.hist(data['X2'])
plt.xlabel('X2')
plt.title('Variable distribution plot of X2')
plt.show()

plt.scatter(x='X1', y='X2', data=data)
plt.xlabel('X1')
plt.ylabel('X2')
plt.title('Scatter plot of X1 vs X2')
plt.show()

# Spliting into independent and target variables using data splicing
X = data.iloc[:,:2]
y = data.iloc[:,2:]

# Spliting the data into traina and test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Scaling the independent variable/predictor variable to imporve model performance.

scaler = MinMaxScaler()
scaler.fit(X_train)
scaled_X_train = scaler.transform(X_train)
scaled_X_test = scaler.transform(X_test)

X_train.shape, y_train.shape

input_dim = X_train.shape[0]
input_dim

# Constructing a deep neural network model

model = Sequential()
model.add(layers.Dense(256, activation='relu', input_shape=(2,)))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

# Compiling the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Model training
model_history = model.fit(scaled_X_train, y_train, epochs=20, batch_size=32,
                    validation_data=(scaled_X_test, y_test))

# Evaluate the model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
print(f'Test Accuracy: {accuracy * 100:.2f}%')

from tensorflow.keras.utils import plot_model

plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

train_loss = model_history.history['loss']
val_loss = model_history.history['val_loss']


epochs = range(1, len(train_loss) + 1)  # Assuming you have recorded losses for each epoch

plt.figure(figsize=(10, 5))

# Plotting the training and validation loss
plt.plot(epochs, train_loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')


# Adding labels and title
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Display the plot
plt.show()

"""#The trend of the validation and training loss is generally decreasing along the epochs, how ever, just before epoch 20, training loss began to increase"""

train_accuracy = model_history.history['accuracy']
val_accuracy = model_history.history['val_accuracy']




epochs = range(1, len(train_loss) + 1)  # Assuming you have recorded losses for each epoch

plt.figure(figsize=(10, 5))

# Plotting the training and validation loss
plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')
plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')


# Adding labels and title
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Display the plot
plt.show()

"""#The trend of the accuracy us upwards and similar to the losses, while validation accuracy is still increasing towards eoch number 20, the training accuracy had began to drop"""